
    \documentclass{resume}

    \begin{document}
    \name{Janvita Reddy}
\details{979-709-1497} {reddyjanvita11@gmail.com} {linkedin.com/in/janvita/}{github.com/JanvitaReddy11}
\begin{rSection}{Education}

\begin{rSubsectionedu}{Texas A\&M University}{College Station, TX, USA}{Aug 23 - May 25}{MS in Data Science}{Data Science}{4.0/4.0}

\end{rSubsectionedu}
\vspace{-15pt}

\begin{rSubsectionedu}{Sardar Vallabhbhai National Institute of Technology}{Surat, India}{Aug 19 - May 23}{B.Tech in Mechanical Engineering}{Mechanical Engineering}{9.21/10.0}

\end{rSubsectionedu}
\vspace{-15pt}
\end{rSection}
\begin{rSection}{Skills}
\begin{itemize}[left=0pt, label={}, align=parleft]
\vspace{-5pt}
\item [] \textbf{Programming languages}: {Python}, {R}, {SQL}, {MATLAB}
\vspace{-5pt}
\item [] \textbf{Ml libraries}: {NumPy}, {Matplotlib}, {Pandas}, {PyTorch}, {Keras}, {OpenCV}, {TensorFlow}, {Scikit}, {Seaborn}, {NLTK}
\vspace{-5pt}
\item [] \textbf{Models}: {Regression}, {SVM}, {KNN}, {Decision Trees}, {Neural Networks}, {Transformers}, {Autoencoders}, {GANs}, {LLMs}
\vspace{-5pt}
\item [] \textbf{Cloud products}: {GCP Compute Engine}, {Cloud storage}, {Vertex AI}, {BigQuery}, {AWS EC2}, {AWS S3}, {SageMaker}
\vspace{-5pt}
\item [] \textbf{Data technology}: {Hadoop}, {PySpark}, {Docker}, {Airflow}, {Git}, {MongoDB}, {Tableau}, {PowerBI}, {Lookup}, {Excel}
\vspace{-5pt}
\item [] \textbf{Analytical skills}: {Image processing}, {CNN}, {LSTM}, {YOLOv5}, {K-means clustering}, {Grad-CAM}, {adversarial learning}, {domain generalization}
\vspace{-5pt}
\item [] \textbf{Miscellaneous}: {robotic welding}, {natural language processing (NLP)}, {machine learning (ML)}, {deep learning (DL)}
\end{itemize}
\end{rSection}
\begin{rSection}{Work Experience}
\vspace{-3pt}

\begin{rSubsectionWork}{Graduate Research Assistant}{Texas A\&M University}{USA}{Jan 24 - Present}

\vspace{-3pt}
\item Annotated over 1800 images using LabelMe software integrated with SAM to identify cotton balls, ensuring data quality for machine learning model development.
\vspace{-3pt}
\item Engineered and implemented segmentation models, including Unet attention, CBAM, Pix2Pix Unet, and SwinUnet, achieving a 0.70 IoU score and enhancing model performance through LoRA and skip connections.
\vspace{-3pt}
\item Conducted correlation analysis between pixels and cotton yield, achieving a 0.91 correlation accuracy and providing insights for crop yield prediction.
\end{rSubsectionWork}
\vspace{-3pt}

\begin{rSubsectionWork}{Graduate Research Assistant}{Texas A\&M University}{USA}{Sep 23 - Dec 23}

\vspace{-3pt}
\item Experimented with CNN models, including AlexNet, VGG-16, ResNet, EfficientNet, and 3D CNN, for classification of stress-induced crops, and conducted hyperparameter tuning using Keras Tuner.
\vspace{-3pt}
\item Implemented an LSTM model on time series images of cotton crops to capture spatio-temporal relations, resulting in a 6\% accuracy improvement on test data, with an F1 score of 0.97.
\end{rSubsectionWork}
\vspace{-3pt}

\begin{rSubsectionWork}{Research Intern}{IISER Bhopal}{India}{May 22 - July 22}

\vspace{-3pt}
\item Designed and developed a domain generalization model to improve resilience across multiple domains, utilizing adversarial learning for model adaptation and Grad-CAM for better interpretability.
\vspace{-3pt}
\item Applied K-means clustering to segregate domains and used AlexNet as a feature extractor, achieving a 3\% increase in accuracy over the baseline model through the incorporation of multi-domain discriminators.
\end{rSubsectionWork}
\vspace{-3pt}

\begin{rSubsectionWork}{Research Intern}{IIT Kharagpur}{India}{May 21 - Feb 22}

\vspace{-3pt}
\item Automated the detection of weld path by developing a machine learning algorithm for robotic welding, leveraging YOLOv5 for joint detection with 99.5\% precision.
\vspace{-3pt}
\item Utilized image processing techniques to denoise and identify edges, yielding an absolute error of Â±1mm for weld lines and Â±0.1mm for gaps.
\end{rSubsectionWork}
\end{rSection}
\begin{rSection}{Projects}
\vspace{-3pt}

    \begin{rSubsectionProj}{AI Assistant}

    \vspace{-3pt}
\item Developed a personal AI assistant that automates tasks like sending emails, scheduling meetings, performing internet searches, and answering queries from PDFs, leveraging RAG for multi-document querying and context-aware responses.
\vspace{-3pt}
\item Integrated specialized agents into a unified master agent using ReAct framework for seamless task execution, ensuring efficient automation of tasks.
\end{rSubsectionProj}
\vspace{-3pt}

    \begin{rSubsectionProj}{Reproducing ChatGPT}

    \vspace{-3pt}
\item Trained GPT-2 124M model from scratch on FineWeb dataset, achieving a significant improvement in HellaSwag accuracy from 0.31 to 0.33 through enhancements such as replacing LayerNorm with RMSNorm and incorporating Rotary Positional Encodings.
\vspace{-3pt}
\item Implemented Group Query Attention to optimize multi-head attention, resulting in improved model performance.
\end{rSubsectionProj}
\vspace{-3pt}

    \begin{rSubsectionProj}{Job Recommendation System}

    \vspace{-3pt}
\item Designed and developed a personalized job recommendation system by analyzing users' work history, applying text preprocessing techniques to transform job description and user profile to word2vec embeddings and TF-IDF vector.
\vspace{-3pt}
\item Modeled a neural ranker using user collaborative filtering, achieving 89\% accuracy and a hit rate of 0.78, providing users with relevant job recommendations.
\end{rSubsectionProj}
\vspace{-3pt}

    \begin{rSubsectionProj}{Wide Residual Attention Networks}

    \vspace{-3pt}
\item Enhanced ResNet model by adding mask attention after residual blocks, resulting in improved model performance and achieving 95.4\% accuracy on the CIFAR-10 dataset.
\vspace{-3pt}
\item Applied normalization, random flipping, and Gaussian noise to training images, ensuring robustness and generalizability of the model.
\end{rSubsectionProj}
\vspace{-3pt}

    \begin{rSubsectionProj}{Chicken Disease Classification using MLOps}

    \vspace{-3pt}
\item Designed a scalable ML solution by integrating pre-trained VGG16 with custom layers, executing data ingestion, training, and evaluation using DVC for pipeline tracking.
\vspace{-3pt}
\item Deployed model using Docker on AWS EC2, leveraging GitHub Actions for automated CI/CD pipelines, ensuring efficient model deployment and management.
\end{rSubsectionProj}
\vspace{-3pt}

    \begin{rSubsectionProj}{Fraud Classification using GCP}

    \vspace{-3pt}
\item Collected and stored employee data in GCS bucket, transforming data and masking sensitive information using Cloud Data Fusion.
\vspace{-3pt}
\item Created dashboards using Looker and automated ETL process with Airflow, enabling data-driven insights and efficient data management.
\end{rSubsectionProj}
\end{rSection}
\end{document}